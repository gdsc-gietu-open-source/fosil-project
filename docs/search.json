[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The purpose of this site is to help foster open science in linguistics (FOSIL). The early 2010’s saw the reproducibility crisis take hold of the psychological sciences. As a consequence, there’s been a push for increased transparency and reproducible methodology to help mitigate the effects of questionable research practices. The resulting methodological framework and associated techniques, now referred to as open science, have reshaped research methods in psychology and have slowly but surely made their way into adjacent fields, such as linguistics. Important considerations often overlooked in the wake of the open science movement deal with (1) how linguists actually learn open science practices and (2) how senior researchers can train the next generation of linguists. Few, if any, researchers have had explicit instruction on the practices of open science as part of their professional training. Nonetheless, today’s speech researcher is expected to be up to date on the current protocols of open science in order incorporate the methodological practices aimed at improving reproducibility/replicability. The FOSIL project aims to make open science practices clear and accessible to people conducting research in the field of linguistics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fostering Open Science in Linguistics",
    "section": "",
    "text": "reproduciblecode/projects\n\n\n\n\npositionalitystatements\n\n\n\n\nregisteredreports\n\n\n\n\npreprints\n\n\n\n\npreregistration\n\n\n\n\nliterateprogramming\n\n\n\n\nopen data"
  },
  {
    "objectID": "posts/literate-programming/index.html",
    "href": "posts/literate-programming/index.html",
    "title": "Literate programming",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol"
  },
  {
    "objectID": "posts/literate-programming/index.html#reporting-descriptive-statistics",
    "href": "posts/literate-programming/index.html#reporting-descriptive-statistics",
    "title": "Literate programming",
    "section": "Reporting descriptive statistics",
    "text": "Reporting descriptive statistics\nIn general all, inline reporting occurs in Rmardown between backticks, i.e., ` `. Specifically, you have to wrap the r code with `r ` to integrate it into your document. For instance, if we want to report the overall mean for the column DurationOfPrefix, we can simply put r code such as, mean(durationsGe$DurationOfPrefix) between to back ticks like this:\n\n\nThe mean duration is `r mean(durationsGe$DurationOfPrefix)`. \n\n\n\nWhich would be rendered as:\n\nThe mean duration is 0.1252515\n\nThere are several decimal points here, though! We probably don’t want that, so if we haven’t rounded the data previously, we can do so inline by using the round function:\n\n\nThe mean duration was `r round(mean(durationsGe$DurationOfPrefix), digits = 2)`. \n\n\n\nNow the code is rendered in prose as:\n\nThe mean duration was 0.13.\n\nAs you can see, this can get rather long in a hurry. Another option is to use an code chunk to calculate summary statistics and assign them to objects. Then you can simply use the objects with inline chunks. For instance, we likely also want to report how many participants are in our dataset. Let’s do this and report it in prose.\n\nCodemean_duration  &lt;- round(mean(durationsGe$DurationOfPrefix), digits = 2)\nn_participants &lt;- length(unique(durationsGe$Speaker))\n\n\n\n\nThere were `r n_participants` participants. \nThe mean duration was `r mean_duration`. \n\n\n\n\nThere were 132 participants. The mean duration was 0.13."
  },
  {
    "objectID": "posts/literate-programming/index.html#reporting-results-of-statistical-models",
    "href": "posts/literate-programming/index.html#reporting-results-of-statistical-models",
    "title": "Literate programming",
    "section": "Reporting results of statistical models",
    "text": "Reporting results of statistical models\nWe can also report the output statistical models and tests. Typically, the results of these tests can be stored in an object in R and extracted. I will provide an example with a t-test in R. First, we will run a t-test to see whether duration varies as a function of speaker sex:\n\nCodet_test_object &lt;- t.test(DurationOfPrefix ~ Sex, data = durationsGe)\nt_test_object\n\n\n    Welch Two Sample t-test\n\ndata:  DurationOfPrefix by Sex\nt = -0.1949, df = 413.26, p-value = 0.8456\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -0.009955279  0.008159221\nsample estimates:\nmean in group female   mean in group male \n           0.1249141            0.1258121 \n\n\nFor a t-test, in APA guidelines we report degrees of freedom, the t-value, and the p-value. All of these are actually stored in the object we just created, and we can automate the reporting process.\nNote: The degree of freedom in this dataset are exaggerated due to the nested structure of the data and this t-test serves as an example only\nDegrees of Freedom\n\n\n`r round(t_test_object$parameter, digits = 2)`. \n\n\n\n\n413.26\n\nThe t-value\n\n\n`r round(t_test_object$statistic, digits = 2)`. \n\n\n\n\n-0.19\n\nThe p-value\n\n\n`r round(t_test_object$p.value, digits = 2)`. \n\n\n\n\n0.85\n\nAll together\n\n\nt = (`r round(t_test_object$parameter, digits = 2)`) =\n`r round(t_test_object$statistic, digits = 2)`, p = \n`r round(t_test_object$p.value, digits = 2)`.   \n\n\n\n\nt = (413.26) = -0.19, p = 0.85."
  },
  {
    "objectID": "posts/literate-programming/index_cp.html",
    "href": "posts/literate-programming/index_cp.html",
    "title": "Literate programming",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話"
  },
  {
    "objectID": "posts/literate-programming/index_cp.html#reporting-descriptive-statistics",
    "href": "posts/literate-programming/index_cp.html#reporting-descriptive-statistics",
    "title": "Literate programming",
    "section": "Reporting descriptive statistics",
    "text": "Reporting descriptive statistics\nIn general all, inline reporting occurs in Rmardown between backticks, i.e., ` `. Specifically, you have to wrap the r code with `r ` to integrate it into your document. For instance, if we want to report the overall mean for the column DurationOfPrefix, we can simply put r code such as, mean(durationsGe$DurationOfPrefix) between to back ticks like this:\n\n\nThe mean duration is `r mean(durationsGe$DurationOfPrefix)`. \n\n\n\nWhich would be rendered as:\n\nThe mean duration is 0.1252515\n\nThere are several decimal points here, though! We probably don’t want that, so if we haven’t rounded the data previously, we can do so inline by using the round function:\n\n\nThe mean duration was `r round(mean(durationsGe$DurationOfPrefix), digits = 2)`. \n\n\n\nNow the code is rendered in prose as:\n\nThe mean duration was 0.13.\n\nAs you can see, this can get rather long in a hurry. Another option is to use an code chunk to calculate summary statistics and assign them to objects. Then you can simply use the objects with inline chunks. For instance, we likely also want to report how many participants are in our dataset. Let’s do this and report it in prose.\n\nCodemean_duration  &lt;- round(mean(durationsGe$DurationOfPrefix), digits = 2)\nn_participants &lt;- length(unique(durationsGe$Speaker))\n\n\n\n\nThere were `r n_participants` participants. \nThe mean duration was `r mean_duration`. \n\n\n\n\nThere were 132 participants. The mean duration was 0.13."
  },
  {
    "objectID": "posts/literate-programming/index_cp.html#reporting-results-of-statistical-models",
    "href": "posts/literate-programming/index_cp.html#reporting-results-of-statistical-models",
    "title": "Literate programming",
    "section": "Reporting results of statistical models",
    "text": "Reporting results of statistical models\nWe can also report the output statistical models and tests. Typically, the results of these tests can be stored in an object in R and extracted. I will provide an example with a t-test in R. First, we will run a t-test to see whether duration varies as a function of speaker sex:\n\nCodet_test_object &lt;- t.test(DurationOfPrefix ~ Sex, data = durationsGe)\nt_test_object\n\n\n    Welch Two Sample t-test\n\ndata:  DurationOfPrefix by Sex\nt = -0.1949, df = 413.26, p-value = 0.8456\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -0.009955279  0.008159221\nsample estimates:\nmean in group female   mean in group male \n           0.1249141            0.1258121 \n\n\nFor a t-test, in APA guidelines we report degrees of freedom, the t-value, and the p-value. All of these are actually stored in the object we just created, and we can automate the reporting process.\nNote: The degree of freedom in this dataset are exaggerated due to the nested structure of the data and this t-test serves as an example only\nDegrees of Freedom\n\n\n`r round(t_test_object$parameter, digits = 2)`. \n\n\n\n\n413.26\n\nThe t-value\n\n\n`r round(t_test_object$statistic, digits = 2)`. \n\n\n\n\n-0.19\n\nThe p-value\n\n\n`r round(t_test_object$p.value, digits = 2)`. \n\n\n\n\n0.85\n\nAll together\n\n\nt = (`r round(t_test_object$parameter, digits = 2)`) =\n`r round(t_test_object$statistic, digits = 2)`, p = \n`r round(t_test_object$p.value, digits = 2)`.   \n\n\n\n\nt = (413.26) = -0.19, p = 0.85."
  },
  {
    "objectID": "posts/open-data/index.html",
    "href": "posts/open-data/index.html",
    "title": "Open data",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol\nOpen data in linguistics has been recently postulated to fuel ethical research practices triggered by the reproducibility crisis in the field. A crisis in research can be defined as a situation in which many research studies cannot be reproduced due to the lack of supporting materials. Although major publishing journals now require access to raw data, this is not unique to linguistics, as it mirrors the reproducibility crisis experienced in fields such as biology or psychology.\nAccess to raw data and the entire process of decision-making is a need in linguistics, as the ability to trust and construct on previous knowledge is the fundamental tool of research development. In this tutorial, we explain why and how you can do this and become a better researcher.\nFigure 1: This is a caption"
  },
  {
    "objectID": "posts/open-data/index.html#why-make-your-data-publicly-available",
    "href": "posts/open-data/index.html#why-make-your-data-publicly-available",
    "title": "Open data",
    "section": "Why make your data publicly available?",
    "text": "Why make your data publicly available?\nMaking data available, as well as the entire decision-making process, is a necessary practice not only to account for variability in results due to the decision making process, but also to inappropriate research techniques, such as HARKing, p-hacking, and selective reporting of positive results. Sharing your data and making it publicly available has a triangular benefit, as it benefits the researcher, the community, and society. Starting with the researcher, it enhances visibility, as it is becoming a growing strength, reduces inefficiencies, improves connections, and, more importantly, makes you, the researcher, gain greater recognition, credibility, validity, and discoverability. Additionally, it benefits the research community, as your data and procedures can be used to form new researchers, reduce unnecessary experiments, improve long-term archiving, and, more significantly, enable replication. Finally, we can inform society by enabling public understanding, promoting science, increasing innovation, and providing the world with easier access to our findings.\nLinguistics is still developing a posture regarding open science and data availability. Several initiatives are trying to increase the accessibility of raw data extracted from research studies, incentivizing the voluntary sharing of all materials and procedures used during the research process.\nPrivately, storing your data over time can be more complicated than you might think. Storage drives can get lost, but if they do not, a hard drive will fail at some point, this is an unavoidable problem associated with the aging of technology.\nSo, what can you do to protect your linguistic data?\nAs with everything in life, as a researcher, you can make your data available in several ways and degrees, depending on the focus of your research project. An extended platform is OSF, https://osf.io/, a Web tool designed to help researchers collaboratively manage, store, and share their research process and files related to their research.\nSharing your data publicly also allows the preservation of the data for future reanalysis. Nevertheless, the linguistic field and language study is broad, with plenty of variabilities and degrees. Therefore, a general concern lies in the ability to share data related to human subject participants. To answer this question, you first need to look at your kind of study: is it a lab phonetics study? Is it a sociolinguistics video interview? Is it an eye-tracking study?\nWhile sharing data from phonetics studies is more accessible, as identifiers can be easily removed, other linguistics branches, such as sociolinguistics, which might involve video recordings of the participants, could represent a more significant concern. Some alternatives to make your data publicly available are submitting transcriptions, removing any video components, or signing waivers with participants who took the study. Of course, the ultimate decision must be taken according to the legality and the researcher’s criteria.\nAs a PI, you should decide what information can make your research more reproducible and share as much information as possible so you, your research community, and society can understand your work more deeply.\nTo sum up, open data is important in scientific research for several reasons:\n\nReproducibility: Open data allows other researchers to access and verify the findings of a study. This is important for ensuring the reproducibility of scientific research.\nCollaboration: Open data allows researchers from different disciplines and institutions to collaborate on research projects. This can lead to new insights and discoveries that might not have been possible otherwise.\nEfficiency: Open data can help to reduce duplication of effort and resources by allowing researchers to build upon the work of others. This can lead to faster and more efficient scientific progress.\nTransparency: Open data promotes transparency in scientific research by allowing others to see the raw data behind the conclusions of a study. This can help to reduce the potential for bias or fraud.\nInnovation: Open data can lead to new and unexpected discoveries by allowing researchers to explore data sets in new ways or apply new techniques to existing data.\n\nOverall, open data can help to improve the quality and impact of scientific research by promoting transparency, collaboration, and innovation."
  },
  {
    "objectID": "posts/positionality-statements/index.html",
    "href": "posts/positionality-statements/index.html",
    "title": "Positionality statements",
    "section": "",
    "text": "Language \n\n\nEnglish\nA positionality statement is a reflective piece of writing that acknowledges the researcher’s stance—or positionality—toward a research topic, framework, and even participants. One’s positionality encompasses their social, cultural, and personal identity, as well as their biases and assumptions (Darwin Holmes 2020), and can influence how research is done and how results are interpreted (Rowe 2014). While positionality statements have been adopted for a while in the social sciences, they are a relatively new incorporation in the field of linguistics, appearing primarily in studies that are of a qualitative nature. We advocate for developing and including positionality statements in linguistic research, as a way of increasing transparency and promoting critical self-reflection in research.\nWhy is important to consider one’s positionality in research and, specifically, in linguistic research? It is essential to consider one’s positionality when conducting or engaging in research because it can impact how data is collected, analyzed, and interpreted. Linguistic research, in particular, often deals with social phenomena that are influenced by language use and the cultural context in which it occurs. Recognizing one’s positionality in linguistic research is crucial to understanding how it might influence the research process and findings.\nWhy should positionality statements be included in quantitative research as well? Traditionally, positionality statements have been more prevalent in qualitative research; nonetheless, they should be considered equally important in quantitative research. Aside from contributing to ongoing efforts to promote transparency and openness in research practices, recognizing and addressing the researcher’s positionality can increase the validity of the findings."
  },
  {
    "objectID": "posts/positionality-statements/index.html#things-to-consider",
    "href": "posts/positionality-statements/index.html#things-to-consider",
    "title": "Positionality statements",
    "section": "Things to Consider",
    "text": "Things to Consider\nResearchers should reflect on their positionality before starting a project and write a positionality statement. When submitting a study for publication, the positionality statement can be included in additional materials if the word limit is a concern. Moreover, in showing their commitment to DEIB (Diversity, Equity, Inclusivity, and Belonging) initiatives, journals have started to encourage authors to include positionality statements with their submissions (see the Journal of Social and Personal Relationships). In sum, positionality statements are critical in linguistic research as they promote critical self-reflection, increase transparency, and help address diversity and inclusivity gaps. Including positionality statements in quantitative research can increase the validity of findings. By reflecting on who it is that does the research, linguistics can become a more diverse, inclusive, and transparent field."
  },
  {
    "objectID": "posts/preprints/index.html",
    "href": "posts/preprints/index.html",
    "title": "Preprints",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol\n\n\n\n\nIn recent years, the concept of open science has gained traction in academic circles. The idea behind open science is to make scientific research and data more accessible, transparent, and reproducible. One of the ways in which open science is being promoted is through the use of pre-prints.\nA pre-print is a version of a research article that has not yet undergone peer review but is publicly available online. Pre-prints allow researchers to share their findings with the scientific community and get feedback before their work is published in a traditional academic journal. This process can speed up the dissemination of knowledge and facilitate collaboration between researchers.\nPre-prints have become increasingly popular in recent years, particularly in fields such as biology, physics, and computer science. The adoption of pre-prints has been slower in some fields, such as the social sciences and humanities, but this is changing as more researchers become aware of the benefits of open science.\nOne of the primary benefits of pre-prints is that they allow researchers to share their findings quickly and easily. This can be especially important in fields where research moves quickly, such as biology or computer science. Pre-prints also allow researchers to receive feedback on their work from their peers, which can help to improve the quality of their research.\nPre-prints also promote transparency and reproducibility in scientific research. By making research findings available to the public before they are peer-reviewed, pre-prints allow others to review and replicate the research. This helps to ensure that the findings are accurate and reliable.\nAnother benefit of pre-prints is that they can help to reduce publication bias. Publication bias occurs when positive results are more likely to be published than negative results. This can skew the scientific literature and lead to a misunderstanding of the state of the research. Pre-prints can help to reduce publication bias by making all research findings available to the public, regardless of the outcome.\nDespite these benefits, some researchers remain hesitant to use pre-prints. One concern is that publishing a pre-print may harm their chances of being published in a traditional academic journal. However, this concern is becoming less relevant as more journals are accepting pre-prints as a legitimate form of publication.\nIn conclusion, pre-prints play an important role in open science by promoting transparency, reproducibility, and collaboration. While some researchers may still be hesitant to use pre-prints, the benefits of open science are becoming increasingly clear. By embracing pre-prints, researchers can accelerate the dissemination of knowledge, improve the quality of research, and ensure that their findings are available to the widest possible audience.\n\n\n\nCitationBibTeX citation:@online{v. casillas2023,\n  author = {V. Casillas, Joseph},\n  title = {Preprints},\n  date = {2023-03-21},\n  url = {https://FOSIL-project.github.io/preprints/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nV. Casillas, Joseph. 2023. “Preprints.” FOSIL. March 21,\n2023. https://FOSIL-project.github.io/preprints/index.html."
  },
  {
    "objectID": "posts/preregistration/index.html",
    "href": "posts/preregistration/index.html",
    "title": "Preregistration",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol"
  },
  {
    "objectID": "posts/preregistration/index.html#what-is-preregistration",
    "href": "posts/preregistration/index.html#what-is-preregistration",
    "title": "Preregistration",
    "section": "What is preregistration?",
    "text": "What is preregistration?\nA preregistration is a timestamped document that includes details about a study, such as research questions, hypotheses, methods, and analytic strategies. Preregistration differs from other open science practices, such as registered reports and preprints, in that it is written prior to data collection and is not peer reviewed. The amount of detail included in a preregistration can vary. In the simplest case, a preregistration can comprise merely a hypothesis or perhaps a brief description of the methods. On the other extreme, a detailed preregistration can include code, power analyses, participant exclusion criteria, etc., in addition to the information described in the simple case. In the following sections, we will provide more information about the different components that can be included in a preregistration with a specific focus on how preregistration can benefit linguistic research. More concretely, we will cover the who, why, what, and how for preregistering your study in linguistics."
  },
  {
    "objectID": "posts/preregistration/index.html#who-can-benefit-from-preregistration",
    "href": "posts/preregistration/index.html#who-can-benefit-from-preregistration",
    "title": "Preregistration",
    "section": "Who can benefit from preregistration?",
    "text": "Who can benefit from preregistration?\nEverybody! Preregistration is an important practice for conducting open science and anyone interested in reducing the likelihood of committing questionable research practices (QRPs) and making their research more transparent should consider using them. This tutorial focuses specifically on preregistration for researchers in any area of linguistics."
  },
  {
    "objectID": "posts/preregistration/index.html#why-preregister-your-study",
    "href": "posts/preregistration/index.html#why-preregister-your-study",
    "title": "Preregistration",
    "section": "Why preregister your study?",
    "text": "Why preregister your study?\nResearchers have to make critical choices throughout the process of designing and conducting research. To give a concrete example, consider a phonotician interested in investigating lexical stress. In this case, the researcher would likely focus on some acoustic correlates associated with stress, such as pitch, duration, and/or intensity. Aside from choosing which acoustic correlate(s) to measure, she would also need to specify the domain in which these measurements are taken. Is it the nucleus of the stressed/unstressed syllables? Or perhaps the entire syllable? Where exactly is the measurement taken? The mid-point, perhaps? Or maybe an average over the entire syllable? All of these choices can have crucial consequences on downstream analyses. This type of inherent flexibility is referred to as researcher degrees of freedom. The purpose of preregisteration is to document all of these critical aspects of the study. Furthermore, preregistration can deter individuals from QRPs, such as HARKing or p-hacking, by requiring them to explicitly state critical decisions in the research pipeline prior to ever collecting data.\n\nFor more information about QRPs and how they relate to the replicability crisis see What is open science?.\nThere are many additional benefits to preregistering studies. Preregistration can serve as proof one is engaging in confirmatory data analysis (as opposed to exploratory data analysis), as it establishes a timeline of decisions made before and after data collection. Moreover, by including a greater level of detail in the preregistration, the researcher is forced to think about aspects of their study that might typically be left for a later stage, e.g., statistical analyses. This necessarily requires the researcher to invest more time upfront, but often has the benefit of increasing the likelihood of discovering critical errors in the study design."
  },
  {
    "objectID": "posts/preregistration/index.html#what-should-you-pregister",
    "href": "posts/preregistration/index.html#what-should-you-pregister",
    "title": "Preregistration",
    "section": "What should you pregister?",
    "text": "What should you pregister?\nIn short, you can preregister anything that you think warrants being timestamped prior to conducting your study. What exactly this entails will vary widely depending on your area of linguistics and the type of study you are conducting. To illustrate, we’ll consider a concrete example.\nLet’s imagine you are a psycholinguist preparing an experiment using self-paced reading. You might want to focus on the research questions, hypotheses, and critical details related to the methodology, such as who the participants are, how you plan to recruit them, how many you plan to recruit, etc. You also might consider explaining what the critical variables are that you will manipulate with your design, what transformations you plan to perform on the data, and what modeling strategies you will use for statistical inferences. All of these decisions, while important, might not be applicaple in every situation. To summarize, the type of information included in a preregistration will likely be related to one of the following:\n\nRQ/Hypotheses\nMethod\nAnalysis\n\nImportantly, it may be overwhelming to incorporate all of them in your preregistration if you are just getting started in Open Science. That’s fine. Feel free to pick what you think might be most relevant to your study to begin, and, with time and practice, you will get better at deciding what is relevant for your research.\nLevel of details\nA lot of concerns of putting Open Science into practice or doing preregistration are about the possible overload of “extra work”. On the contrary, preregistration should be helping us work in a more efficient manner both in the long run and in short terms. Besides, you have complete control of how much detail you want to include. The more detailed the preregistration is, the more effort you need to put into, and as a result the less work down the road. Here we only propose some of the levels of details that may help you determine how much details you can incorporate in your preregistration (Figure 2). The darker the shade, the more detailed it is (thus more work). Again, you can always incorporate different levels of details in different parts.\n\n\n\n\nFigure 1: Levels of detail"
  },
  {
    "objectID": "posts/preregistration/index.html#how-to-preregister-your-study",
    "href": "posts/preregistration/index.html#how-to-preregister-your-study",
    "title": "Preregistration",
    "section": "How to preregister your study",
    "text": "How to preregister your study\nThere are websites dedicated to Open Science practices. OSF is one and it provide platform and/or template we can use.\n\n\nOSF\nGithub\nAspredicted.org\nBy hand\n\n\n\n\n\nOSF\n\nStart from scratch\nStart from an existing OSF project or component\n\n\n\n\n\nPre registration involves making a plan for your research project before collecting and analyzing data. This plan can be documented and shared on Github, which is a popular web-based hosting service for version control and collaborative software development.\nHere are the steps to set up a pre registration for your research on Github:\n\nCreate a Github account: If you do not already have a Github account, create one by visiting the Github homepage and following the instructions.\nCreate a new repository: Once you are logged in to Github, you can create a new repository to store your pre registration documents. Click the “New” button in the top left corner of the screen and follow the prompts to create a new repository.\nChoose a template: Github provides several templates for different types of repositories. You can choose a template that is specifically designed for pre registration documents, such as the Open Science Framework (OSF) Preregistration template.\nAdd your pre registration documents: Once you have chosen a template, you can add your pre registration documents to the repository. These documents should include a detailed description of your research question, hypotheses, methods, and analysis plan. You can use Markdown, a lightweight markup language, to format your documents on Github.\nShare your repository: Once your pre registration documents are complete, you can share your repository with other researchers or members of the public. You can do this by sharing the link to your repository or by inviting collaborators to contribute to the project.\nUpdate your repository: As you collect and analyze data, you may need to update your pre registration documents. You can do this by making changes to your documents on Github and committing the changes to the repository.\n\nBy setting up a preregistration on Github, you can make your research more transparent and reproducible. Other researchers can review your plan and provide feedback, and you can use the repository to document any changes you make to your research plan over time.\n\n\n\nOne author creates the pre-registration.\nParticipating authors are emailed, requesting approval.\nIf all approve, it is saved but remains private until an author makes it public; or remains private forever.(Why?)\nAuthors may share an anonymous version of the pre-registration with reviewers.\nIf made public, the final .pdf (sample) is automatically stored in the web-archive.\n\n\n\nWrite, timestamp + freeze, and then check yourself\nTo set up a pre registration for your research from scratch on paper, you can follow these steps:\n\nDefine your research question and hypotheses: Start by identifying the research question you are trying to answer and any hypotheses you have about the expected results.\nSelect your variables and measures: Identify the independent and dependent variables in your study and describe the measures you will use to operationalize these variables.\nDetermine your sample size and recruitment strategy: Specify the number of participants you plan to recruit and describe how you will recruit them.\nOutline your research design: Describe the research design you will use to address your research question, such as a between-subjects or within-subjects design.\nSpecify your data analysis plan: Describe the statistical analyses you plan to use to test your hypotheses, including any planned exploratory analyses and methods to handle missing data.\nPlan for ethical considerations: Address any ethical considerations in your study, such as obtaining informed consent from participants, ensuring confidentiality and privacy, and handling any potential risks or harms.\nConsider any potential limitations: Anticipate any potential limitations of your study, such as sampling bias or measurement error.\nWrite up your pre registration plan: Once you have completed these steps, write up your pre registration plan in a clear and concise manner on paper. Be sure to include all relevant information, such as your research question, hypotheses, variables and measures, sample size and recruitment strategy, research design, data analysis plan, ethical considerations, and potential limitations.\n\n\n\n\nTo read more about preregistration in linguisticis: https://www.degruyter.com/document/doi/10.1515/ling-2019-0048/html?lang=en\nReference Kathawalla, U. K., Silverstein, P., & Syed, M. (2021). Easing into open science: A guide for graduate students and their advisors. Collabra: Psychology, 7(1)"
  },
  {
    "objectID": "posts/registered-reports/index.html",
    "href": "posts/registered-reports/index.html",
    "title": "Registered reports",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol\nThe reproducibility crisis has drawn attention to the shortcomings of the traditional model of publishing scientific research. In the current model, researchers generate hypotheses, design studies, collect data, analyze data, interpret results, and submit their findings for publication. However, this model has been criticized for lending itself to questionable research practices (QRPs), such as p-hacking, harking, and publication bias."
  },
  {
    "objectID": "posts/registered-reports/index.html#attempts-at-reform",
    "href": "posts/registered-reports/index.html#attempts-at-reform",
    "title": "Registered reports",
    "section": "Attempts at reform",
    "text": "Attempts at reform\nTo address these issues, researchers have attempted various reforms, such as meta-analysis and pre-registration. Meta-analysis is a statistical technique that combines the results of multiple studies to increase the power of analysis. Pre-registration involves publicly registering a study’s design and methods before collecting data, to mitigate QRPs."
  },
  {
    "objectID": "posts/registered-reports/index.html#a-new-model",
    "href": "posts/registered-reports/index.html#a-new-model",
    "title": "Registered reports",
    "section": "A New model",
    "text": "A New model\nRegistered Reports (RRs) are a new model that combines pre-registration with peer review. In this model, researchers submit a detailed proposal of their study, including their hypotheses, methods, and analyses, for review before data collection. If the proposal is accepted, the study is guaranteed publication, regardless of the results. This incentivizes rigorous methodology and reduces QRPs, as researchers cannot manipulate their analyses to obtain significant results.\nRRs were first introduced in 2013 by the Center for Open Science (COS), and have since been adopted by many journals across various fields, including psychology, neuroscience, and medicine.\nPre-registration is often confused with RR, but they differ in that pre-registration is a separate step that occurs before the traditional publishing pipeline, whereas RR is integrated into the publishing process. RRs cannot solve all the problems with the current model, but they can help reduce QRPs and increase transparency in scientific research."
  },
  {
    "objectID": "posts/registered-reports/index.html#current-state-future",
    "href": "posts/registered-reports/index.html#current-state-future",
    "title": "Registered reports",
    "section": "Current state, future",
    "text": "Current state, future\nRRs are gaining popularity, but some fields, such as linguistics, have been slow to adopt them. RRs may particularly benefit early-career researchers (ECRs), who can use them to increase their chances of publication and build a reputation for rigor. However, more senior researchers may be resistant to change and may need to be convinced of the benefits of RRs for the field as a whole.\nIn conclusion, Registered Reports represent a promising new model for publishing scientific research that can help reduce QRPs and increase transparency. As more journals adopt RRs, the scientific community can move towards a more rigorous and trustworthy publishing model."
  },
  {
    "objectID": "posts/reproducible-code-projects/index.html",
    "href": "posts/reproducible-code-projects/index.html",
    "title": "Reproducible code/projects",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol\n\n\n\n\nReproducibility is a crucial aspect of any scientific study, and it has become increasingly important in recent years. Researchers must be able to provide a clear and transparent account of their findings, including the methods used to obtain them. Reproducibility can help to ensure that research results are valid, reliable, and can be used by others to build on existing knowledge. In this blog post, we will explore the importance of reproducibility, what we know about it in the fields of psychology and linguistics, and how researchers can make their code and projects more reproducible.\nThe importance of reproducibility cannot be overstated. In general, it helps to increase the credibility of research findings and allows other researchers to verify and build on existing work. At worst, a lack of reproducibility can lead to irreproducible results and wasted resources. This can have serious implications for public health and policy decisions based on research findings.\nIn order to ensure reproducibility, it is necessary to be transparent about the methods used in research. This includes not only the data collection and analysis methods but also the code used to conduct the analysis. In the fields of psychology and linguistics, there is increasing awareness of the importance of reproducibility, and many researchers are taking steps to improve the transparency of their research.\nResearchers have an ethical responsibility to make their code and projects reproducible. There are several steps that researchers can take to make their code and projects more reproducible. One approach is to create reports that document the research process, including the data used, the methods used to analyze the data, and the results obtained. This documentation can then be used to reproduce the research findings.\nAnother approach is to create reproducible projects. These projects include all of the data, code, and documentation necessary to reproduce the research findings. This approach makes it easier for others to reproduce the research findings and build on the work.\nDependency management tools like renv and targets can also be helpful in ensuring reproducibility. These tools help to manage the dependencies that are necessary to run the code and ensure that the code can be run on different systems.\nComputational reproducibility platforms like Binder and Code Ocean can also be used to ensure reproducibility. These platforms allow researchers to share their code and data in a way that can be easily replicated by others.\nIt is important to note that there is no way to future-proof code or projects. Researchers must continually work to maintain the reproducibility of their work. This includes updating the code and documentation as needed and testing the code on different systems to ensure that it can be run in different environments.\nIn conclusion, reproducibility is a crucial aspect of scientific research. It helps to ensure that research findings are valid, reliable, and can be used by others to build on existing knowledge. In the fields of psychology and linguistics, there is increasing awareness of the importance of reproducibility, and many researchers are taking steps to improve the transparency of their research. By creating reports, reproducible projects, and using dependency management tools and computational reproducibility platforms, researchers can make their code and projects more reproducible.\n\n\n\nCitationBibTeX citation:@online{v. casillas2023,\n  author = {V. Casillas, Joseph},\n  title = {Reproducible Code/Projects},\n  date = {2023-03-21},\n  url = {https://FOSIL-project.github.io/reproducible-code-projects/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nV. Casillas, Joseph. 2023. “Reproducible Code/Projects.”\nFOSIL. March 21, 2023. https://FOSIL-project.github.io/reproducible-code-projects/index.html."
  },
  {
    "objectID": "posts/what-is-open-science/index.html",
    "href": "posts/what-is-open-science/index.html",
    "title": "What is open science?",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nहिंदी\n\n\nRomână\n\n\nEspañol\n\n\n\n\nWhat is open science? Parsons et al. (2022) provide the following definition:\n\nAn umbrella term reflecting the idea that scientific knowledge of all kinds, where appropriate, should be openly accessible, transparent, rigorous, reproducible, replicable, accumulative, and inclusive, all which are considered fundamental features of the scientific endeavour. Open science consists of principles and behaviors that promote transparent, credible, reproducible, and accessible science. Open science has six major aspects: open data, open methodology, open source, open access, open peer review, and open educational resources.\n\nThat sounds wonderful, right? But you might be asking yourself why the push for Open Science? It may come as a surprise to some, but the open, transparent research practices described by Parsons et al. (2022) have not been the norm in scholarly research.\nTo properly contextualize the need for Open Science, we have to go back to the early 2010’s. Around this time, several fields of research embarked on large-scale replication projects to scrutinize some of their major findings. One example of these projects took place in psychology. This particular project tested whether they could replicate 100 influential findings (Open Science Collaboration 2015). They found the approximately 53% of the findings did not replicate. This project inspired similar large-scale replication projects in other fields, yielding similar results in economics (Camerer et al. 2016), social sciences (Camerer et al. 2018), and cancer research (Errington et al. 2021). These alarming findings are now referred to as the replication (or reproducibility) crisis. Researchers have pointed to questionable research practices (QRPs), p-hacking, HARKing, small sample sizes, poor theory, lack of transparency, etc. as factors that ultimately led to the replication crisis, though it is likely that other factors are at play.\n\nTake a second to consider your field of study. How many important findings do you think would replicate? If you were to replicate 100 of the most influential findings, how many would need to replicate for you to have confidence in your field?\n\nIn the aftermath of the replication crisis we have seen a push for increased transparency and reproducible methodology to help mitigate the effects of questionable research practices. The resulting methodological framework and associated techniques have reshaped research methods in psychology and have slowly but surely made their way into adjacent fields. This website is dedicated to making open science practices understandable and accessible to researchers in the speech sciences from all backgrounds and at every stage, from students/early career researchers to senior researchers.\nTo this end, we have highlighted 7 areas in which speech researchers can engage in Open Science:\n\nLiterate programming\nOpen data\nPositionality statements\nPreprints\nPreregistration\nRegistered reports\nReproducible code/projects\n\nThroughout this website you will find tutorials designed to get you up and running in each of these areas so that you can engage in Open Science practices.\nSee Figure 1\n\n\n\n\n\nFigure 1: This is a caption\n\n\n\n\n\n\n\n\n\nReferences\n\nCamerer, Colin F, Anna Dreber, Eskil Forsell, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2016. “Evaluating Replicability of Laboratory Experiments in Economics.” Science 351 (6280): 1433–36. https://doi.org/10.1126/science.aaf091.\n\n\nCamerer, Colin F, Anna Dreber, Felix Holzmeister, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2018. “Evaluating the Replicability of Social Science Experiments in Nature and Science Between 2010 and 2015.” Nature Human Behaviour 2 (9): 637–44. https://doi.org/10.1038/s41562-018-0399-z.\n\n\nErrington, Timothy M, Maya Mathur, Courtney K Soderberg, Alexandria Denis, Nicole Perfito, Elizabeth Iorns, and Brian A Nosek. 2021. “Investigating the Replicability of Preclinical Cancer Biology.” Elife 10: e71601. https://doi.org/10.7554/eLife.71601.\n\n\nOpen Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716. https://doi.org/10.1126/science.aac4716.\n\n\nParsons, Sam, Flávio Azevedo, Mahmoud M Elsherif, Samuel Guay, Owen N Shahim, Gisela H Govaart, Emma Norris, et al. 2022. “A Community-Sourced Glossary of Open Scholarship Terms.” Nature Human Behaviour 6 (3): 312–18. https://doi.org/10.1038/s41562-021-01269-4.\n\nCitationBibTeX citation:@online{v. casillas2023,\n  author = {V. Casillas, Joseph},\n  title = {What Is Open Science?},\n  date = {2023-02-21},\n  url = {https://FOSIL-project.github.io/what-is-open-science/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nV. Casillas, Joseph. 2023. “What Is Open Science?” FOSIL.\nFebruary 21, 2023. https://FOSIL-project.github.io/what-is-open-science/index.html."
  },
  {
    "objectID": "posts/what-is-open-science/index_cp.html",
    "href": "posts/what-is-open-science/index_cp.html",
    "title": "What is open science?",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol\n\n\n\n\n即將推出\n\n\n\nCitationBibTeX citation:@online{v. casillas2023,\n  author = {V. Casillas, Joseph},\n  title = {What Is Open Science?},\n  date = {2023-02-21},\n  url = {https://FOSIL-project.github.io/what-is-open-science/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nV. Casillas, Joseph. 2023. “What Is Open Science?” FOSIL.\nFebruary 21, 2023. https://FOSIL-project.github.io/what-is-open-science/index.html."
  },
  {
    "objectID": "posts/what-is-open-science/index_fr.html",
    "href": "posts/what-is-open-science/index_fr.html",
    "title": "What is open science?",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol\n\n\n\n\nProchainement\n\n\n\nCitationBibTeX citation:@online{v. casillas2023,\n  author = {V. Casillas, Joseph},\n  title = {What Is Open Science?},\n  date = {2023-02-21},\n  url = {https://FOSIL-project.github.io/what-is-open-science/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nV. Casillas, Joseph. 2023. “What Is Open Science?” FOSIL.\nFebruary 21, 2023. https://FOSIL-project.github.io/what-is-open-science/index.html."
  },
  {
    "objectID": "posts/what-is-open-science/index_hi.html",
    "href": "posts/what-is-open-science/index_hi.html",
    "title": "खुला विज्ञानं क्या है?",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nहिंदी\n\n\nRomână\n\n\nEspañol\n\n\n\n\nखुली विज्ञान क्या है? Parsons et al. (2022) कहता है कि:\n\nयह एक सामान्य शब्द है जो वैज्ञानिक ज्ञान का आदान-प्रदान, स्पष्ट, कठिन, पुनर्निर्माणीय, पुनर्विकसनीय, संचित और समावेशी होने का विचार करने के लिए है, जो सभी किस्म के वैज्ञानिक यातात्म्यता के महत्वपूर्ण लक्षण माने जाते हैं। मुक्त विज्ञान का अर्थ है ऐसे सिद्धांत और व्यवहार रखना जो पारदर्शी, विश्वसनीय, प्रतिलिपि प्रस्तुत करने योग्य और सुलभ विज्ञान को बढ़ावा दें। खुली विज्ञान के छह प्रमुख पहलु होते हैं : खुली डेटा, खुला उपाय, खुला स्रोत, खुली पहुंच, खुली सहयोगात्मक नवाचार, और खुले शैक्षिक संसाधन।\n\nयह सुनने में अच्छा लगता है, ना? लेकिन सवाल यह है की खुले विज्ञान पर क्यों जोर दिया जा रहा है? यह आपको चौंका सकता है, लेकिन Parsons et al. (2022) द्वारा वर्णित पारदर्शी प्रथाएँ वैज्ञानिक शोध में आम नहीं होतीं।\nखुली विज्ञान की आवश्यकता को सही संदर्भ में रखने के लिए, हमें 2010 के दशक में वापस जाना होगा। इस समय के आसपास, कई अनुसंधान क्षेत्रों ने अपने मुख्य निष्कर्ष की जांच करने के लिए बड़े पैमाने पर पुनरावृत्ति परियोजनाओं की शुरुआत की। एक उदाहरण है मनोविज्ञान में एक परियोजना। इस विशेष परियोजना में यह जांची गई कि क्या वे 100 प्रभावशाली निष्कर्ष को पुनर्निर्धारित कर सकते हैं (Open Science Collaboration 2015)। उन्होंने पाया कि लगभग 53% निष्कर्ष का पुनर्निर्धारण नहीं हुआ।\nउल्लिखित परियोजना ने अन्य क्षेत्रों में समान बड़े पुनरावृत्ति परियोजनाओं को प्रेरित किया, जिनसे अर्थशास्त्र (Camerer et al. 2016), सामाजिक विज्ञान (Camerer et al. 2018), और कैंसर अनुसंधान (Errington et al. 2021) में समान नतीजे प्राप्त हुए। ये भयानक निष्कर्ष अब पुनरावृत्ति (या पुनर्उत्पादनशीलता) संकट के रूप में उल्लेख किए जाते हैं। शोधकर्ताओं ने कहा है कि संदेहास्पद अनुसंधान विधियाँ (“क्यूआरपी”), “पी-हैकिंग”, HARKing, छोटे नमूने का उपयोग, खराब सिद्धांत, पारदर्शिता की कमी, आदि ऐसे कारक थे जो आखिरकार पुनरावृत्ति संकट में मुख्य भूमिका निभाई, हालांकि संभावना है, कि अन्य कारक भी खेल रहे हों।\n\nअपने अध्ययन क्षेत्र को ध्यान से विचारें। आपको लगता है कि कितने महत्वपूर्ण निष्कर्ष पुनरावृत्ति होंगे? यदि आप 100 सबसे प्रभावशाली निष्कर्षों को दोहराते हैं, तो आपको अपने क्षेत्र में आत्मविश्वास के लिए कितने निष्कर्षों की आवश्यकता होगी?\n\nपुनरावृत्ति संकट के बाद हमने देखा है कि संदेहास्पद अनुसंधान विधियों के प्रभाव को कम करने के लिए वृद्धि की गई पारदर्शिता और पुनर्उत्पादनशील विधियों पर जोर दिया गया है। इसके परिणामस्वरूप विधिशास्त्रीय ढांचा और संबंधित तकनीकों ने मनोविज्ञान में शोध विधियों को पुनर्रूपीकृत किया है और इन्हें सम्बद्ध क्षेत्रों में प्रस्तुत किया गया है।\nयह वेबसाइट खुली विज्ञान के अभ्यासों को समझने और सभी पृष्ठभूमियों और हर स्तर पर भाषा विज्ञान के शोधकर्ताओं के लिए सुलभ और समझने योग्य बनाने के लिए समर्पित है, अनुसंधान के शुरू से लेकर वरिष्ठ शोधकर्ताओं तक।\nइस दिशा में, हमने भाषाई शोधकर्ताओं को खुली विज्ञान में जुड़ने के लिए 7 क्षेत्रों को शामिल किया है:\n\nसाहित्यात्मक प्रोग्रामिंग\nखुली डेटा\nस्थितिवाचकता विवरण\nप्रीप्रिंट्स\nप्री-रजिस्ट्रेशन\nपंजीकृत रिपोर्ट्स\nपुनरावृत्तीय कोड/परियोजनाएँ\n\nइस वेबसाइट के माध्यम से आपको इन सभी क्षेत्रों में शुरू होने और चलने के लिए डिज़ाइन किए गए ट्यूटोरियल्स मिलेंगे, ताकि आप खुली विज्ञान के अभ्यास में शामिल हो सकें।\nSee Figure 1\n\n\n\n\n\nFigure 1: This is a caption\n\n\n\n\n\n\n\n\nReferences\n\nCamerer, Colin F, Anna Dreber, Eskil Forsell, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2016. “Evaluating Replicability of Laboratory Experiments in Economics.” Science 351 (6280): 1433–36. https://doi.org/10.1126/science.aaf091.\n\n\nCamerer, Colin F, Anna Dreber, Felix Holzmeister, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2018. “Evaluating the Replicability of Social Science Experiments in Nature and Science Between 2010 and 2015.” Nature Human Behaviour 2 (9): 637–44. https://doi.org/10.1038/s41562-018-0399-z.\n\n\nErrington, Timothy M, Maya Mathur, Courtney K Soderberg, Alexandria Denis, Nicole Perfito, Elizabeth Iorns, and Brian A Nosek. 2021. “Investigating the Replicability of Preclinical Cancer Biology.” Elife 10: e71601. https://doi.org/10.7554/eLife.71601.\n\n\nOpen Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716. https://doi.org/10.1126/science.aac4716.\n\n\nParsons, Sam, Flávio Azevedo, Mahmoud M Elsherif, Samuel Guay, Owen N Shahim, Gisela H Govaart, Emma Norris, et al. 2022. “A Community-Sourced Glossary of Open Scholarship Terms.” Nature Human Behaviour 6 (3): 312–18. https://doi.org/10.1038/s41562-021-01269-4.\n\nCitationBibTeX citation:@online{laungani2023,\n  author = {Laungani, Krishita},\n  title = {खुला {विज्ञानं} {क्या} {है?}},\n  date = {2023-02-21},\n  url = {https://FOSIL-project.github.io/what-is-open-science/index_hi.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nLaungani, Krishita. 2023. “खुला विज्ञानं क्या है?” FOSIL.\nFebruary 21, 2023. https://FOSIL-project.github.io/what-is-open-science/index_hi.html."
  },
  {
    "objectID": "posts/what-is-open-science/index_ro.html",
    "href": "posts/what-is-open-science/index_ro.html",
    "title": "What is open science?",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol\n\n\n\n\nin curand\n\n\n\nCitationBibTeX citation:@online{v. casillas2023,\n  author = {V. Casillas, Joseph},\n  title = {What Is Open Science?},\n  date = {2023-02-21},\n  url = {https://FOSIL-project.github.io/what-is-open-science/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nV. Casillas, Joseph. 2023. “What Is Open Science?” FOSIL.\nFebruary 21, 2023. https://FOSIL-project.github.io/what-is-open-science/index.html."
  },
  {
    "objectID": "posts/what-is-open-science/index_sp.html",
    "href": "posts/what-is-open-science/index_sp.html",
    "title": "What is open science?",
    "section": "",
    "text": "Language \n\n\nEnglish\n\n\n官話\n\n\nFrançais\n\n\nRomână\n\n\nEspañol\n\n\n\n\n¡Próximamente!\n\n\n\nCitationBibTeX citation:@online{v. casillas2023,\n  author = {V. Casillas, Joseph},\n  title = {What Is Open Science?},\n  date = {2023-02-21},\n  url = {https://FOSIL-project.github.io/what-is-open-science/index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nV. Casillas, Joseph. 2023. “What Is Open Science?” FOSIL.\nFebruary 21, 2023. https://FOSIL-project.github.io/what-is-open-science/index.html."
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nPreregistration\n\n\n\n\n\n\n\nopen science\n\n\nreregistration\n\n\n\n\nAll about preregistration\n\n\n\n\n\n\nNov 21, 2023\n\n\nJiawei Shao, Adrija Gadamsetty, Katherine Taveras\n\n\n\n\n\n\n  \n\n\n\n\nReproducible code/projects\n\n\n\n\n\n\n\nopen science\n\n\nreproducibility\n\n\ntransparency\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n  \n\n\n\n\nPositionality statements\n\n\n\n\n\n\n\nopen science\n\n\npositionality statements\n\n\ntransparency\n\n\n\n\nRecognizing the Researcher’s Perspective in Linguistic Research\n\n\n\n\n\n\nMar 21, 2023\n\n\nGabriela Constantin-Dureci, Joseph V. Casillas\n\n\n\n\n\n\n  \n\n\n\n\nRegistered reports\n\n\n\n\n\n\n\nopen science\n\n\nregistered reports\n\n\ntransparency\n\n\n\n\nA new model for publishing scientific research\n\n\n\n\n\n\nMar 21, 2023\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n  \n\n\n\n\nPreprints\n\n\n\n\n\n\n\nopen science\n\n\nregistered reports\n\n\ntransparency\n\n\n\n\nWhy you should consider posting preprints of your linguistic research.\n\n\n\n\n\n\nMar 21, 2023\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n  \n\n\n\n\nOpen data\n\n\n\n\n\n\n\nopen science\n\n\nopen data\n\n\ntransparency\n\n\n\n\nWhy you should share your data.\n\n\n\n\n\n\nMar 21, 2023\n\n\nIvan Andreu Rascón, Isabelle Chang\n\n\n\n\n\n\n  \n\n\n\n\nWhat is open science?\n\n\n\n\n\n\n\ninfo\n\n\n\n\nA quick primer on Open Science and reproducible research.\n\n\n\n\n\n\nFeb 21, 2023\n\n\nJoseph V. Casillas\n\n\n\n\n\n\n  \n\n\n\n\nLiterate programming\n\n\n\n\n\n\n\ninfo\n\n\ncoding\n\n\nliterate programming\n\n\n\n\nIntroduction to literate programming.\n\n\n\n\n\n\nFeb 20, 2023\n\n\nKyle Parrish, Isabelle Chang\n\n\n\n\n\n\nNo matching items"
  }
]